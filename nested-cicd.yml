
AWSTemplateFormatVersion: 2010-09-09
Transform:
  - 'AWS::Serverless-2016-10-31'
Description: 'CICD Pipeline for all Cirrus applications'
Parameters:
 QSS3BucketName:
    AllowedPattern: '^[0-9a-zA-Z]+([0-9a-zA-Z-]*[0-9a-zA-Z])*$'
    ConstraintDescription: >-
      Quick Start bucket name can include numbers, lowercase letters, uppercase
      letters, and hyphens (-). It cannot start or end with a hyphen (-).
    Default: aws-quickstart
    Description: >-
      S3 bucket name for the Quick Start assets. Quick Start bucket name can
      include numbers, lowercase letters, uppercase letters, and hyphens (-). It
      cannot start or end with a hyphen (-).
    Type: String
 QSS3KeyPrefix:
    AllowedPattern: '^[0-9a-zA-Z-/]*$'
    ConstraintDescription: >-
      Quick Start key prefix can include numbers, lowercase letters, uppercase
      letters, hyphens (-), and forward slash (/).
    Default: quickstart-git2s3/
    Description: >-
      S3 key prefix for the Quick Start assets. Quick Start key prefix can
      include numbers, lowercase letters, uppercase letters, hyphens (-), and
      forward slash (/).
    Type: String
 OutputBucketName:
    Description: >-
      OPTIONAL: Bucket Name where the zip file output should be placed, if left
      blank a bucket name will be automatically generated.
    Type: String
    Default: ''
 SourceObjectKey:
  Description: 'S3 source artifact'
  Type: String
  Default: sudusan/nested-stack/sudusan_nested-stack.zip
 SourceObjectKeyForProd:
  Description: 'S3 source artificat for production'
  Type: String
  Default: master/bundle.zip
 ChangeSetName:
  Description: 'Name of application'
  Type: String
  Default: myapp-changeset
 ApplicationName:
  Description: 'Name of application'
  Type: String
  Default: myapp
 EnvironmentClass:
  Description: 'Environment being deployed into'
  Type: String
  AllowedValues:
      - 'PRD'
      - 'STG'
 PreDeployBuildSpec:
  Description: 'Name of the buildspec file for pre-deployment testing'
  Type: String
  Default: buildspec.yml
 PostDeployBuildSpec:
  Description: 'Name of the buildspec file for post-deployment testing'
  Type: String
  Default: testspec.yml
 StageAccountId:
  Description: The AWS Account ID of the Stage account. Leave as default if EnvironmentClass is not "PROD"
  Type: String
  Default: 805262168568
 StageLambdaRole:
  Description: The AWS IAM Role of the Stage account's Lambda execution role. Leave as default if EnvironmentClass is not "PROD"
  Type: String
  Default: nested-stack-1-LambdaServiceRole-75YSS4DTTJGB
 ProdBucketName:
  Description: The Name of the production bucket that S3 will post to if codepipeline executes successfully.
  Type: String
  Default: nested-stack-prd-1-codepipelineartifactstorebucke-1w3946kjgippf
 SlackWebhookUrl:
    Description: Incoming Webhook url for slack after you create your app, store and encrypt in parameter store, It should be of form {{resolve:ssm-secure:<key-name>:<version>}}'
    Type: String
    Default: 'https://hooks.slack.com/services/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'
 SlackChannel:
    Description: Slack Channel where approvals needs to be sent
    Type: String
    Default: sudu-personal-app
 SlackVerifToken:
    Description: slack verification token of the app, store and encrypt in parameter store, It should be of form {{resolve:ssm-secure:<key-name>:<version>}}'
    Type: String
    Default: pnw7eCdZEcekQ6Cgomq0kCjF
 SlackApprovalMembers:
    Description: List of AD account of the member who can perform the slack approval for CICD.
    Type: String
    Default: t_sanksu   
 NotificationsSNSTopic:
    Description: ARN of the SNS topic that will be used for notifications on the pipeline (if not specified a new one will be created).
    Type: String
    Default: ''
 AllowedIps:
    Default: 0.0.0.0/0
    Description: gitpull method only. Comma seperated list of IP CIDR blocks for source
      IP authentication. The Autodesk external IP range is provided as default.
    Type: String   
 ApiSecret:
    Default: ''
    Description: 'gitpull method only. WebHook Secrets for use with GitHub Enterprise
      and GitLab. If a secret is matched IP range authentication is bypassed. Cannot
      contain: , \ "'
    NoEcho: 'true'
    Type: String
  
Conditions:
  
  ProdS3Bucket: !Equals [ !Ref EnvironmentClass , PRD]
  NonProdS3Bucket: !Not [!Equals [ !Ref EnvironmentClass , PRD]]
  STGEnvironment: !Equals [ !Ref EnvironmentClass, STG]
  NotSTGEnvironment: !Not [ !Equals [ !Ref EnvironmentClass, STG]]
  CreateNewSNSTopic: !Equals [!Ref NotificationsSNSTopic, '']
  UseAllowedIps: !Not [!Equals [ !Ref AllowedIps, '']]
  UseApiSecret: !Not [!Equals [ !Ref ApiSecret, '']]
  AutoGenOutputBucketName: !Not 
    - !Equals 
      - !Ref OutputBucketName
      - ''
Resources:
  # Sns topic to subscribe to approval request lambda function
  ConfigTable:
    Condition: STGEnvironment
    Properties:
      AttributeDefinitions:
      - AttributeName: branch
        AttributeType: S
      KeySchema:
      - AttributeName: branch
        KeyType: HASH
      ProvisionedThroughput:
        ReadCapacityUnits: 1
        WriteCapacityUnits: 1
    Type: AWS::DynamoDB::Table
  
  LambdaZipsBucket:
    Condition: STGEnvironment
    Type: 'AWS::S3::Bucket'
    Properties:
      Tags: []
  CopyZips:
    Condition: STGEnvironment
    Type: 'AWS::CloudFormation::CustomResource'
    Properties:
      ServiceToken: !GetAtt 
        - CopyZipsFunction
        - Arn
      DestBucket: !Ref LambdaZipsBucket
      SourceBucket: !Ref QSS3BucketName
      Prefix: !Ref QSS3KeyPrefix
      Objects:
        - functions/packages/CreateSSHKey/lambda.zip
        - functions/packages/DeleteBucketContents/lambda.zip
        - functions/packages/GitPullS3/lambda.zip
        - functions/packages/ZipDl/lambda.zip
  CopyZipsRole:
    Condition: STGEnvironment
    Type: 'AWS::IAM::Role'
    Properties:
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: 'sts:AssumeRole'
      ManagedPolicyArns:
        - 'arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole'
      Path: /
      Policies:
        - PolicyName: lambda-copier
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Effect: Allow
                Action:
                  - 's3:GetObject'
                Resource:
                  - !Sub 'arn:aws:s3:::${QSS3BucketName}/${QSS3KeyPrefix}*'
              - Effect: Allow
                Action:
                  - 's3:PutObject'
                  - 's3:DeleteObject'
                Resource:
                  - !Sub 'arn:aws:s3:::${LambdaZipsBucket}/${QSS3KeyPrefix}*'
  CopyZipsFunction:
    Condition: STGEnvironment
    Type: 'AWS::Lambda::Function'
    Properties:
      Description: Copies objects from a source S3 bucket to a destination
      Handler: index.handler
      Runtime: python2.7
      Role: !GetAtt 
        - CopyZipsRole
        - Arn
      Timeout: 240
      Code:
        ZipFile: !Join 
          - |+

          - - import json
            - import logging
            - import threading
            - import boto3
            - import cfnresponse
            - ''
            - ''
            - 'def copy_objects(source_bucket, dest_bucket, prefix, objects):'
            - '    s3 = boto3.client(''s3'')'
            - '    for o in objects:'
            - '        key = prefix + o'
            - '        copy_source = {'
            - '            ''Bucket'': source_bucket,'
            - '            ''Key'': key'
            - '        }'
            - '        s3.copy_object(CopySource=copy_source, Bucket=dest_bucket, Key=key)'
            - ''
            - ''
            - 'def delete_objects(bucket, prefix, objects):'
            - '    s3 = boto3.client(''s3'')'
            - '    objects = {''Objects'': [{''Key'': prefix + o} for o in objects]}'
            - '    s3.delete_objects(Bucket=bucket, Delete=objects)'
            - ''
            - ''
            - 'def timeout(event, context):'
            - '    logging.error(''Execution is about to time out, sending failure response to CloudFormation'')'
            - '    cfnresponse.send(event, context, cfnresponse.FAILED, {}, None)'
            - ''
            - ''
            - 'def handler(event, context):'
            - '    # make sure we send a failure to CloudFormation if the function is going to timeout'
            - '    timer = threading.Timer((context.get_remaining_time_in_millis() / 1000.00) - 0.5, timeout, args=[event, context])'
            - '    timer.start()'
            - ''
            - '    print(''Received event: %s'' % json.dumps(event))'
            - '    status = cfnresponse.SUCCESS'
            - '    try:'
            - '        source_bucket = event[''ResourceProperties''][''SourceBucket'']'
            - '        dest_bucket = event[''ResourceProperties''][''DestBucket'']'
            - '        prefix = event[''ResourceProperties''][''Prefix'']'
            - '        objects = event[''ResourceProperties''][''Objects'']'
            - '        if event[''RequestType''] == ''Delete'':'
            - '            delete_objects(dest_bucket, prefix, objects)'
            - '        else:'
            - '            copy_objects(source_bucket, dest_bucket, prefix, objects)'
            - '    except Exception as e:'
            - '        logging.error(''Exception: %s'' % e, exc_info=True)'
            - '        status = cfnresponse.FAILED'
            - '    finally:'
            - '        timer.cancel()'
            - '        cfnresponse.send(event, context, status, {}, None)'
            - ''
  KeyBucket:
    Condition: STGEnvironment
    Type: 'AWS::S3::Bucket'
    Properties:
      Tags: []
  OutputBucket:
    Type: 'AWS::S3::Bucket'
    Properties:
      BucketName: !If 
        - AutoGenOutputBucketName
        - !Ref OutputBucketName
        - !Ref 'AWS::NoValue'
      VersioningConfiguration:
        Status: Enabled
      Tags: []
  KMSKey:
    Condition: STGEnvironment
    Type: 'AWS::KMS::Key'
    Properties:
      Description: >-
        git CodePipeline integration, used to encrypt/decrypt ssh keys stored in
        S3
      KeyPolicy:
        Version: 2012-10-17
        Statement:
          - Sid: Allow access for Key Administrators
            Effect: Allow
            Principal:
              AWS:
                - !Join 
                  - ''
                  - - 'arn:aws:iam::'
                    - !Ref 'AWS::AccountId'
                    - ':root'
            Action:
              - 'kms:Create*'
              - 'kms:Describe*'
              - 'kms:Enable*'
              - 'kms:List*'
              - 'kms:Put*'
              - 'kms:Update*'
              - 'kms:Revoke*'
              - 'kms:Disable*'
              - 'kms:Get*'
              - 'kms:Delete*'
              - 'kms:ScheduleKeyDeletion'
              - 'kms:CancelKeyDeletion'
            Resource: '*'
          - Sid: Allow use of the key
            Effect: Allow
            Principal:
              AWS:
                - !Join 
                  - ''
                  - - 'arn:aws:iam::'
                    - !Ref 'AWS::AccountId'
                    - ':root'
            Action:
              - 'kms:Encrypt'
              - 'kms:Decrypt'
              - 'kms:ReEncrypt*'
              - 'kms:GenerateDataKey*'
              - 'kms:DescribeKey'
            Resource: '*'
          - Sid: Allow attachment of persistent resources
            Effect: Allow
            Principal:
              AWS:
                - !Join 
                  - ''
                  - - 'arn:aws:iam::'
                    - !Ref 'AWS::AccountId'
                    - ':root'
            Action:
              - 'kms:CreateGrant'
              - 'kms:ListGrants'
              - 'kms:RevokeGrant'
            Resource: '*'
            Condition:
              Bool:
                'kms:GrantIsForAWSResource': true
  CreateSSHKeyRole:
    Condition: STGEnvironment
    Type: 'AWS::IAM::Role'
    Properties:
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: 'sts:AssumeRole'
      Path: /
      Policies:
        - PolicyName: git2cp-sshkeygen
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Effect: Allow
                Action:
                  - 's3:GetObject'
                Resource:
                  - !Join 
                    - ''
                    - - 'arn:aws:s3:::'
                      - !Ref KeyBucket
                      - /crypto.zip
              - Effect: Allow
                Action:
                  - 's3:PutObject'
                Resource:
                  - !Join 
                    - ''
                    - - 'arn:aws:s3:::'
                      - !Ref KeyBucket
                      - /enc_key
              - Effect: Allow
                Action:
                  - 'kms:Encrypt'
                Resource:
                  - !GetAtt 
                    - KMSKey
                    - Arn
              - Effect: Allow
                Action:
                  - 'logs:CreateLogGroup'
                  - 'logs:CreateLogStream'
                  - 'logs:PutLogEvents'
                Resource:
                  - 'arn:aws:logs:*:*:*'
  CreateSSHKeyLambda:
    Condition: STGEnvironment
    DependsOn: CopyZips
    Type: 'AWS::Lambda::Function'
    Properties:
      Handler: lambda_function.lambda_handler
      MemorySize: '128'
      Role: !GetAtt 
        - CreateSSHKeyRole
        - Arn
      Runtime: python2.7
      Timeout: '300'
      Code:
        S3Bucket: !Ref LambdaZipsBucket
        S3Key: !Sub '${QSS3KeyPrefix}functions/packages/CreateSSHKey/lambda.zip'
  CreateSSHKey:
    Condition: STGEnvironment
    Type: 'AWS::CloudFormation::CustomResource'
    Version: '1.0'
    Properties:
      ServiceToken: !GetAtt 
        - CreateSSHKeyLambda
        - Arn
      KeyBucket: !Ref KeyBucket
      Region: !Ref 'AWS::Region'
      KMSKey: !Ref KMSKey
  
  DeleteBucketContentsRole:
    Condition: STGEnvironment
    Type: 'AWS::IAM::Role'
    Properties:
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: 'sts:AssumeRole'
      Path: /
      Policies:
        - PolicyName: git2cp-deletebucketcontents
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Effect: Allow
                Action:
                  - 's3:*'
                Resource:
                  - !Join 
                    - ''
                    - - 'arn:aws:s3:::'
                      - !Ref KeyBucket
                      - /*
                  - !Join 
                    - ''
                    - - 'arn:aws:s3:::'
                      - !Ref OutputBucket
                      - /*
                  - !Join 
                    - ''
                    - - 'arn:aws:s3:::'
                      - !Ref KeyBucket
                  - !Join 
                    - ''
                    - - 'arn:aws:s3:::'
                      - !Ref OutputBucket
              - Effect: Allow
                Action:
                  - 'logs:CreateLogGroup'
                  - 'logs:CreateLogStream'
                  - 'logs:PutLogEvents'
                Resource:
                  - 'arn:aws:logs:*:*:*'
  
  DeleteBucketContentsLambda:
    Condition: STGEnvironment
    DependsOn: CopyZips
    Type: 'AWS::Lambda::Function'
    Properties:
      Handler: lambda_function.lambda_handler
      MemorySize: '128'
      Role: !GetAtt 
        - DeleteBucketContentsRole
        - Arn
      Runtime: python2.7
      Timeout: '300'
      Code:
        S3Bucket: !Ref LambdaZipsBucket
        S3Key: !Sub '${QSS3KeyPrefix}functions/packages/DeleteBucketContents/lambda.zip'
  
  DeleteBucketContents:
    Condition: STGEnvironment
    Type: 'AWS::CloudFormation::CustomResource'
    Version: '1.0'
    DependsOn:
      - KeyBucket
      - OutputBucket
    Properties:
      ServiceToken: !GetAtt 
        - DeleteBucketContentsLambda
        - Arn
      KeyBucket: !Ref KeyBucket
      OutputBucket: !Ref OutputBucket
  
  GitPullRole:
    Condition: STGEnvironment
    Type: 'AWS::IAM::Role'
    Properties:
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: 'sts:AssumeRole'
      Path: /
      Policies:
        - PolicyName: git2cp-gitpull
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Effect: Allow
                Action:
                  - 'kms:Decrypt'
                Resource:
                  - !GetAtt 
                    - KMSKey
                    - Arn
              - Effect: Allow
                Action:
                  - 's3:PutObject'
                Resource:
                  - !Join 
                    - ''
                    - - 'arn:aws:s3:::'
                      - !Ref OutputBucket
                  - !Join 
                    - ''
                    - - 'arn:aws:s3:::'
                      - !Ref OutputBucket
                      - /*
              - Effect: Allow
                Action:
                  - 's3:GetObject'
                Resource:
                  - !Join 
                    - ''
                    - - 'arn:aws:s3:::'
                      - !Ref KeyBucket
                      - /enc_key
              - Effect: Allow
                Action:
                  - 'logs:CreateLogGroup'
                  - 'logs:CreateLogStream'
                  - 'logs:PutLogEvents'
                Resource:
                  - 'arn:aws:logs:*:*:*'
  
  GitPullLambda:
    Condition: STGEnvironment
    DependsOn: CopyZips
    Type: 'AWS::Lambda::Function'
    Properties:
      Handler: lambda_function.lambda_handler
      MemorySize: 128
      Role: !GetAtt 
        - GitPullRole
        - Arn
      Runtime: python2.7
      Timeout: 300
      Environment:
        Variables:
          ExcludeGit: 'True'
      Code:
        S3Bucket: !Ref LambdaZipsBucket
        S3Key: !Sub '${QSS3KeyPrefix}functions/packages/GitPullS3/lambda.zip'
  
  WebHookRole:
    Condition: STGEnvironment
    Type: 'AWS::IAM::Role'
    Properties:
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service: apigateway.amazonaws.com
            Action: 'sts:AssumeRole'
      Path: /
      ManagedPolicyArns:
        - >-
          arn:aws:iam::aws:policy/service-role/AmazonAPIGatewayPushToCloudWatchLogs
      Policies:
        - PolicyName: git2cp-webhook
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Effect: Allow
                Action:
                  - 'lambda:InvokeAsync'
                  - 'lambda:InvokeFunction'
                Resource:
                  - !GetAtt 
                    - GitPullLambda
                    - Arn
  
  
  WebHookApi:
    Condition: STGEnvironment
    Properties:
      Body:
        definitions:
          Empty:
            type: object
        info:
          title:
            Fn::Join:
            - ''
            - - G2CP-
              - Ref: AWS::StackName
          version: '2016-07-26T07:34:38Z'
        paths:
          /gitpull:
            post:
              consumes:
              - application/json
              produces:
              - application/json
              responses:
                '200':
                  description: 200 response
                  schema:
                    $ref: '#/definitions/Empty'
              x-amazon-apigateway-integration:
                credentials:
                  Fn::GetAtt:
                  - WebHookRole
                  - Arn
                httpMethod: POST
                passthroughBehavior: when_no_templates
                requestParameters:
                  integration.request.header.X-Amz-Invocation-Type: '''Event'''
                requestTemplates:
                  application/json:
                    Fn::Join:
                    - ''
                    - - '#set($allParams = $input.params())

                        '
                      - '{

                        '
                      - '"body-json" : $input.json(''$''),

                        '
                      - '"params" : {

                        '
                      - '#foreach($type in $allParams.keySet())

                        '
                      - '    #set($params = $allParams.get($type))

                        '
                      - '"$type" : {

                        '
                      - '    #foreach($paramName in $params.keySet())

                        '
                      - '    "$paramName" : "$util.escapeJavaScript($params.get($paramName))"

                        '
                      - '        #if($foreach.hasNext),#end

                        '
                      - '    #end

                        '
                      - '}

                        '
                      - '    #if($foreach.hasNext),#end

                        '
                      - '#end

                        '
                      - '},

                        '
                      - '"stage-variables" : {

                        '
                      - '#foreach($key in $stageVariables.keySet())

                        '
                      - '"$key" : "$util.escapeJavaScript($stageVariables.get($key))"

                        '
                      - '    #if($foreach.hasNext),#end

                        '
                      - '#end

                        '
                      - '},

                        '
                      - '"context" : {

                        '
                      - '    "account-id" : "$context.identity.accountId",

                        '
                      - '    "api-id" : "$context.apiId",

                        '
                      - '    "api-key" : "$context.identity.apiKey",

                        '
                      - '    "authorizer-principal-id" : "$context.authorizer.principalId",

                        '
                      - '    "caller" : "$context.identity.caller",

                        '
                      - '    "cognito-authentication-provider" : "$context.identity.cognitoAuthenticationProvider",

                        '
                      - '    "cognito-authentication-type" : "$context.identity.cognitoAuthenticationType",

                        '
                      - '    "cognito-identity-id" : "$context.identity.cognitoIdentityId",

                        '
                      - '    "cognito-identity-pool-id" : "$context.identity.cognitoIdentityPoolId",

                        '
                      - '    "http-method" : "$context.httpMethod",

                        '
                      - '    "stage" : "$context.stage",

                        '
                      - '    "source-ip" : "$context.identity.sourceIp",

                        '
                      - '    "user" : "$context.identity.user",

                        '
                      - '    "user-agent" : "$context.identity.userAgent",

                        '
                      - '    "user-arn" : "$context.identity.userArn",

                        '
                      - '    "request-id" : "$context.requestId",

                        '
                      - '    "resource-id" : "$context.resourceId",

                        '
                      - '    "resource-path" : "$context.resourcePath",

                        '
                      - '    "allowed-ips" : "$stageVariables.allowedips",

                        '
                      - '    "api-secrets" : "$stageVariables.apisecrets",

                        '
                      - '    "key-bucket" : "'
                      - Ref: KeyBucket
                      - '",
                        '
                      - '    "output-bucket" : "$stageVariables.outputbucket",
                        '
                      - '    "public-key" : "'
                      - Ref: CreateSSHKey
                      - '",
                        '
                      - '    "raw-body" : "$util.escapeJavaScript($input.body)"
                        '
                      - '    }
                        '
                      - '}'
                responses:
                  default:
                    statusCode: '200'
                type: aws
                uri:
                  Fn::Join:
                  - ''
                  - - 'arn:aws:apigateway:'
                    - Ref: AWS::Region
                    - :lambda:path//2015-03-31/functions/
                    - Fn::GetAtt:
                      - GitPullLambda
                      - Arn
                    - /invocations
        schemes:
        - https
        securityDefinitions:
          sigv4:
            in: header
            name: Authorization
            type: apiKey
            x-amazon-apigateway-authtype: awsSigv4
        swagger: '2.0'
    Type: AWS::ApiGateway::RestApi


  WebHookApiDeployment:
    Condition: STGEnvironment
    Properties:
      RestApiId:
        Ref: WebHookApi
      StageName: DummyStage
    Type: AWS::ApiGateway::Deployment
  WebHookApiProdStage:
    Condition: STGEnvironment
    Properties:
      DeploymentId:
        Ref: WebHookApiDeployment
      RestApiId:
        Ref: WebHookApi
      StageName: Prod
      Variables:
        allowedips:
          Fn::If:
          - UseAllowedIps
          - Ref: AllowedIps
          - Ref: AWS::NoValue
        apisecrets:
          Fn::If:
          - UseApiSecret
          - Ref: ApiSecret
          - Ref: AWS::NoValue
        outputbucket:
          Ref: OutputBucket
    Type: AWS::ApiGateway::Stage
  

  CodePipelineSNSTopic:
    Type: 'AWS::SNS::Topic'
    Condition: NotSTGEnvironment
    Properties:
      Subscription:
        - Endpoint: !GetAtt 'ApprovalRequesterFunction.Arn'
          Protocol: lambda
  
  pipelinesevent:
    Type: 'AWS::SNS::Topic'
    Condition: NotSTGEnvironment
    Properties:
      Subscription:
        - Endpoint: !GetAtt 'Codepipelinestatusfunction.Arn'
          Protocol: lambda

  pipelineseventrule:    
    DependsOn: PipelineSNSTopicPolicy
    Type: AWS::Events::Rule
    Condition: NotSTGEnvironment
    Properties: 
      EventPattern: 
        source: 
          - "aws.codepipeline"
        detail-type: 
          - "CodePipeline Pipeline Execution State Change"
        detail:
          state:
            - "STARTED"
            - "SUCCEEDED"
            - "FAILED"
      State: "ENABLED"            
      Targets: 
        - 
          Arn: 
            Ref: "pipelinesevent" 
          Id: "PipelineNotificationTopic"
          InputTransformer:
            InputPathsMap:
              Pipeline: "$.detail.pipeline"
              Status: "$.detail.state"
            InputTemplate: !Sub '":construction_worker: _*The pipeline <Pipeline> has changed state to <Status>*_ :construction_worker:"'

  PipelineSNSTopicPolicy:
    Type: AWS::SNS::TopicPolicy
    Condition: NotSTGEnvironment
    Properties:
      PolicyDocument:
        Id: MyTopicPolicy
        Version: '2012-10-17'
        Statement:
        - Sid: TrustCWEToPublishEventsToMyTopic
          Effect: Allow
          Principal:
            Service: "events.amazonaws.com"
          Action: sns:Publish
          Resource: !Ref pipelinesevent
      Topics:
      - !Ref pipelinesevent  

  # Deployment Approval Requester lambda function
  ApprovalRequesterFunction:
    Type: AWS::Lambda::Function
    Condition: NotSTGEnvironment
    Properties:
      Description: Function to send request for approval or deny to slack.
      Handler: index.handler
      Role: !GetAtt LambdaServiceRole.Arn
      Runtime: python3.7
      Tags:
        - Key: ApplicationName
          Value: !Ref ApplicationName
        - Key: EnvironmentClass
          Value: !Ref EnvironmentClass
      Timeout: 300
      Environment:
        Variables:
          SLACK_WEBHOOK_URL: !Ref 'SlackWebhookUrl'
          CHANGESET_NAME: !Ref 'ChangeSetName'
          SLACK_CHANNEL: !Ref 'SlackChannel'
          STACK_NAME: !Join [ '-', [ !Ref ApplicationName, !Ref EnvironmentClass, 'Stack' ] ]
      #VpcConfig: #Specify for uploading within specific VPCs
      Code:
        ZipFile: |
          import os
          import json
          import logging
          import time
          import boto3
          from urllib.request import Request, urlopen
          logger = logging.getLogger()
          logger.setLevel(logging.INFO)
          def get_changeset_details(stack_name, changeset_name):
            cfnClient = boto3.client('cloudformation')
            try:
              response = cfnClient.describe_change_set(ChangeSetName=changeset_name, StackName=stack_name)
              changes = response['Changes']
              changestring = str(changes)
              newstr = changestring.replace("'", '"')
              csjson = '{"Changes":' + newstr + '}'
              print(csjson)
              return csjson
            except Exception as e:
              logger.error(e)
              return 'failure'
          def handler(event, context):
          # encrypted parameter in Parameter Store.
              SLACK_WEBHOOK_URL = os.environ['SLACK_WEBHOOK_URL']
              SLACK_CHANNEL = os.environ['SLACK_CHANNEL']
              STACK_NAME = os.environ['STACK_NAME']
              CHANGESET_NAME = os.environ['CHANGESET_NAME']
              logger.info("Event: " + str(event))
              message = json.loads(event['Records'][0]['Sns']['Message'])
              logger.info("Message: " + str(message))
              try:
                  data = json.loads(json.dumps(message))
                  token = data["approval"]["token"]
                  codepipeline_name = data["approval"]["pipelineName"]
                  changeset_json = get_changeset_details(STACK_NAME,CHANGESET_NAME)
                  text_line1 = "Your stack `"+STACK_NAME+"` has the following changes:\n"
                  text_string = text_line1 + changeset_json
                  # format of slack message
                  slack_message = {
                      "channel": SLACK_CHANNEL,
                      "text": text_string,
                      "attachments": [
                          {
                              "text": "_Yes to promote and deploy your build_",
                              "fallback": "You are unable to promote a build",
                              "callback_id": "promote_approval",
                              "color": "#3AA3E3",
                              "attachment_type": "default",
                              "actions": [
                                  {
                                      "name": "deployment",
                                      "text": "Yes",
                                      "style": "primary",
                                      "type": "button",
                                      "value": json.dumps({"approve": True, "codePipelineToken": token, "codePipelineName": codepipeline_name}),
                                      "confirm": {
                                          "title": "Are you sure?",
                                          "text": "_This will promote and deploy your build to production_",
                                          "ok_text": "Yes",
                                          "dismiss_text": "No"
                                      }
                                  },
                                  {
                                      "name": "deployment",
                                      "text": "No",
                                      "type": "button",
                                      "value": json.dumps({"approve": False, "codePipelineToken": token, "codePipelineName": codepipeline_name})
                                  }
                              ],
                              "ts": time.time()
                          }
                      ]
                  }
                  #Post slack message with webhook
                  req = Request(SLACK_WEBHOOK_URL, json.dumps(slack_message).encode('utf-8'))
                  response = urlopen(req)
                  response.read()
                  return None
              except Exception as e:
                  return str(e)
  # Permission to invoke lambda function from sns
  ApprovalRequesterPermissionAuthorizerSns:
    Type: AWS::Lambda::Permission
    Condition: NotSTGEnvironment
    Properties:
      FunctionName: !GetAtt 'ApprovalRequesterFunction.Arn'
      Action: lambda:InvokeFunction
      Principal: sns.amazonaws.com
      SourceArn: !Ref CodePipelineSNSTopic

  # Deployment response event function
  ApprovalResponseFunction:
    Type: AWS::Lambda::Function
    Condition: NotSTGEnvironment
    Properties:
      Description: Function to capture response for approval or deny from slack
      Handler: index.handler
      Role: !GetAtt LambdaServiceRole.Arn
      Runtime: python3.7
      Tags:
        - Key: ApplicationName
          Value: !Ref ApplicationName
        - Key: EnvironmentClass
          Value: !Ref EnvironmentClass
      Timeout: 300
      Environment:
        Variables:
          SLACK_VERIFICATION_TOKEN: !Ref 'SlackVerifToken'
          SLACK_USER_APPROVAL: !Ref 'SlackApprovalMembers'
      #VpcConfig: #Specify for uploading within specific VPCs
      Code:
        ZipFile: |  
          # This function is triggered via API Gateway when a user acts on the Slack interactive message sent by approval_requester.py
          from urllib.parse import parse_qs
          import json
          import os
          import boto3
          import logging
          logger = logging.getLogger()
          logger.setLevel(logging.INFO)
          def send_slack_message(action_details,flag):
            if not flag:
              return 
            codepipeline_status = "Approved" if action_details["approve"] else "Rejected"
            codepipeline_name = action_details["codePipelineName"]
            token = action_details["codePipelineToken"]
            #user = action_details["user"]
            client = boto3.client('codepipeline')
            
            response_approval = client.put_approval_result(
                        pipelineName=codepipeline_name,
                        stageName='Approval',
                        actionName='ApproveOrDeny',
                        result={'summary':'','status':codepipeline_status},
                        token=token)
            return response_approval
          #Triggered by API Gateway
          #It kicks off a particular CodePipeline project
          def handler(event, context):
            SLACK_VERIFICATION_TOKEN = os.environ['SLACK_VERIFICATION_TOKEN']
            SLACK_USER_APPROVAL = os.environ['SLACK_USER_APPROVAL'].split(',')
            logger.info("Event: " + str(event))
            try:
              print('inside')
              body = parse_qs(event['body'])
              payload = json.loads(body['payload'][0])
              flag = False
              
              # Validate Slack token
              
              if SLACK_VERIFICATION_TOKEN == payload['token']:
                user = payload["user"]["name"]
                print(payload)
                if user in SLACK_USER_APPROVAL:
                  flag = True
                try:send_slack_message(json.loads(payload['actions'][0]['value']),flag)
                except Exception as err:
                  print(err)
                  
                # This will replace the interactive message with a simple text response.
              print(flag)
              if flag:
                return  {
                  "isBase64Encoded": "false",
                  "statusCode": 200,
                  "body": "{\"text\": \"The approval has been processed\"}"
                }
              else:
                return  {
                  "isBase64Encoded": "false",
                  "statusCode": 403,
                  "body": "{\"error\": \"This request does not include a valid verification token.\"}"
                }
            except Exception as e:
              return {
                "isBase64Encoded": "false",
                "statusCode": 422,
                "body": str(e.__class__.__name__)
              }
  # Permission to invoke lambda function from API gateway
  ApprovalResponsePermissionAuthorizerSns:
    Type: AWS::Lambda::Permission
    Condition: NotSTGEnvironment
    Properties:
      FunctionName: !GetAtt 'ApprovalResponseFunction.Arn'
      Action: lambda:InvokeFunction
      Principal: apigateway.amazonaws.com

  InteractiveMessageApi:
    Type: AWS::Serverless::Api
    Condition: NotSTGEnvironment
    Properties:
      StageName: promote
      DefinitionBody:
        swagger: "2.0"
        info:
          version: "1.0"
          title: "CICD"
          contact:
            email: "sudhakar.sankaran@autodesk.com"
          license:
            name: "Apache 2.0"
            url: "http://www.apache.org/licenses/LICENSE-2.0.html"
        basePath: "/prd"
        schemes:
        - "https"
        paths:
          /interactivemessage:
            post:
              produces:
              - "application/json"
              responses:
                "200":
                  description: "200 response"
                  schema:
                    $ref: "#/definitions/Empty"
              x-amazon-apigateway-integration:
                uri:
                  Fn::Sub: "arn:aws:apigateway:${AWS::Region}:lambda:path/2015-03-31/functions/${ApprovalResponseFunction.Arn}/invocations"
                responses:
                  default:
                    statusCode: "200"
                passthroughBehavior: "when_no_match"
                httpMethod: "POST"
                type: "aws_proxy"
        definitions:
          Empty:
            type: "object"
            title: "Empty Schema"                  

  # Lambda execution role
  LambdaExecRole:
    Type: AWS::IAM::Role
    Condition: NotSTGEnvironment
    Properties:
      AssumeRolePolicyDocument:
        Statement:
        - Action: sts:AssumeRole
          Effect: Allow
          Principal:
            Service:
            - lambda.amazonaws.com
          Sid: ''
      Path: /
      Policies:
      - PolicyName: LambdaAccess
        PolicyDocument:
          Statement:
            - Effect: Allow
              Action:
                - logs:CreateLogGroup
                - logs:CreateLogStream
                - logs:PutLogEvents
                - logs:GetLogEvents
              Resource:
                - arn:aws:logs:*:*:*
            - Effect: Allow
              Resource: '*'
              Action:
                - 'ssm:Get*'
                - 'ssm:Describe*'
                - 'kms:Decrypt'
                - 'kms:Encrypt'
                - 'kms:DescribeKey'
                - 'kms:Get*'
                - 'codepipeline:*'

  CodePipelineArtifactStoreBucket:
    Type: AWS::S3::Bucket
    Properties:
        BucketEncryption:
          ServerSideEncryptionConfiguration:
            - ServerSideEncryptionByDefault:
                SSEAlgorithm: AES256
        #LifecycleConfiguration: Fill me in as-needed for backup retention rates.
        PublicAccessBlockConfiguration:
          BlockPublicAcls: true
          BlockPublicPolicy: true
          IgnorePublicAcls: true
          RestrictPublicBuckets: true
        Tags:
        - Key: EnvironmentClass
          Value: !Ref EnvironmentClass
        - Key: ApplicationName
          Value: !Ref ApplicationName
        VersioningConfiguration:
          Status: Enabled
  CodePipelineArtifactStoreBucketPolicy:
    Type: AWS::S3::BucketPolicy
    Condition: NonProdS3Bucket
    Properties:
      Bucket: !Ref CodePipelineArtifactStoreBucket
      PolicyDocument:
        Version: 2012-10-17
        Statement:
        -
          Sid: DenyUnencryptedObjectUploads
          Effect: Deny
          Principal: '*'
          Action:
          - s3:PutObject
          Resource: !Join [ '', [ !GetAtt CodePipelineArtifactStoreBucket.Arn, '/master/*' ] ]
          Condition:
            StringNotEquals:
              s3:x-amz-server-side-encryption:
                - "AES256"
                - "aws:kms"
        -
          Sid: DenyInsecureConnections
          Effect: Deny
          Principal: '*'
          Action: s3:*
          Resource: !Join [ '', [ !GetAtt CodePipelineArtifactStoreBucket.Arn, '/*' ] ]
          Condition:
            Bool:
              aws:SecureTransport: false
  CodePipelineProdArtifactStoreBucketPolicy:
    Type: AWS::S3::BucketPolicy
    Condition: ProdS3Bucket
    Properties:
      Bucket: !Ref CodePipelineArtifactStoreBucket
      PolicyDocument:
        Version: 2012-10-17
        Statement:
        -
          Sid: AllowStgToReadBucketDetails
          Action:
          - s3:ListBucket
          - s3:GetBucketLocation
          Effect: Allow
          Resource: !GetAtt CodePipelineArtifactStoreBucket.Arn
          Principal:
            AWS: !Sub arn:aws:iam::${StageAccountId}:role/${StageLambdaRole}
        -
          Sid: AllowStgToWriteAndSetPermissions
          Action:
          - s3:PutObject
          - s3:PutObjectAcl
          Effect: Allow
          Resource: !Join [ '', [ !GetAtt CodePipelineArtifactStoreBucket.Arn, '/*' ] ]
          Principal:
            AWS: !Sub arn:aws:iam::${StageAccountId}:role/${StageLambdaRole}
        -
          Sid: DenyUnencryptedObjectUploads
          Effect: Deny
          Principal: '*'
          Action: s3:PutObject
          Resource: !Join [ '', [ !GetAtt CodePipelineArtifactStoreBucket.Arn, '/master/*' ] ]
          Condition:
            StringNotEquals:
              s3:x-amz-server-side-encryption:
                - "AES256"
                - "aws:kms"
        -
          Sid: DenyInsecureConnections
          Effect: Deny
          Principal: '*'
          Action: s3:*
          Resource: !Join [ '', [ !GetAtt CodePipelineArtifactStoreBucket.Arn, '/*' ] ]
          Condition:
            Bool:
              aws:SecureTransport: false
  LambdaServiceRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
        -
          Effect: Allow
          Principal:
            Service:
            - lambda.amazonaws.com
          Action:
          - sts:AssumeRole
      Path: /
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/AWSLambdaExecute
        - arn:aws:iam::aws:policy/AWSCodePipelineCustomActionAccess
        - arn:aws:iam::aws:policy/AWSCodePipelineApproverAccess
      Policies:
      -
        PolicyName: Write-to-S3
        PolicyDocument:
          Version: 2012-10-17
          Statement:
          -
            Effect: Allow
            Action:
            - s3:GetObject
            - s3:PutObject
            - s3:PutObjectAcl
            Resource: '*'
  CodePipelineServiceRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
        -
          Effect: Allow
          Principal:
            Service:
            - codepipeline.amazonaws.com
            - cloudformation.amazonaws.com
            - codebuild.amazonaws.com
            - codedeploy.amazonaws.com

          Action: sts:AssumeRole
      Path: /
      Policies:
      -
        PolicyName: AWS-CodePipeline-Service-3
        PolicyDocument:
          Version: 2012-10-17
          Statement:
          -
            Effect: Allow
            Action:
            - codecommit:CancelUploadArchive
            - codecommit:GetBranch
            - codecommit:GetCommit
            - codecommit:GetUploadArchiveStatus
            - codecommit:UploadArchive
            Resource: '*'
          -
            Effect: Allow
            Action:
            - codedeploy:CreateDeployment
            - codedeploy:GetApplicationRevision
            - codedeploy:GetDeployment
            - codedeploy:GetDeploymentConfig
            - codedeploy:RegisterApplicationRevision
            Resource: '*'
          -
            Effect: Allow
            Action:
            - codebuild:BatchGetBuilds
            - codebuild:StartBuild
            Resource: '*'
          -
            Effect: Allow
            Action:
            - devicefarm:ListProjects
            - devicefarm:ListDevicePools
            - devicefarm:GetRun
            - devicefarm:GetUpload
            - devicefarm:CreateUpload
            - devicefarm:ScheduleRun
            Resource: '*'
          -
            Effect: Allow
            Action:
            - lambda:InvokeFunction
            - lambda:ListFunctions
            Resource: '*'
          -
            Effect: Allow
            Action:
            - iam:PassRole
            - iam:CreateServiceLinkedRole
            - iam:CreateRole
            - iam:GetRolePolicy
            - iam:PutRolePolicy
            - iam:DeleteRolePolicy
            - iam:AttachRolePolicy
            - iam:DetachRolePolicy
            - iam:DeleteRole
            - iam:CreateInstanceProfile
            - iam:DeleteInstanceProfile
            - iam:GetInstanceProfile
            - iam:ListInstanceProfiles
            - iam:AddRoleToInstanceProfile
            - iam:RemoveRoleFromInstanceProfile
            Resource: '*'
          -
            Effect: Allow
            Action:
            - elasticbeanstalk:*
            - ec2:*
            - tag:*
            - elasticloadbalancing:*
            - autoscaling:*
            - cloudwatch:*
            - s3:*
            - sns:*
            - cloudformation:*
            - rds:*
            - sqs:*
            - ecs:*
            - route53:*
            Resource: '*'
  AppPipelineNoUpload:
    Type: AWS::CodePipeline::Pipeline
    Condition: NotSTGEnvironment
    Properties:
      Name: !Join [ '-', [ !Ref ApplicationName, !Ref EnvironmentClass, 'Pipeline' ] ]
      RoleArn:
        !GetAtt CodePipelineServiceRole.Arn
      Stages:
      - Name: Source
        Actions:
        -
          Name: SourceAction
          ActionTypeId:
            Category: Source
            Owner: AWS
            Version: "1"
            Provider: S3
          OutputArtifacts:
            - Name: SourceOutput
          Configuration:
            S3Bucket: !Ref CodePipelineArtifactStoreBucket
            S3ObjectKey: !Ref SourceObjectKeyForProd
            PollForSourceChanges: true
          RunOrder: 1
      - Name: ChangeSet
        Actions:
        - Name: CreateChangeSet
          ActionTypeId:
            Category: Deploy
            Owner: AWS
            Provider: CloudFormation
            Version: "1"
          InputArtifacts:
            - Name: SourceOutput
          Configuration:
            StackName: !Join [ '-', [ !Ref ApplicationName, !Ref EnvironmentClass, 'Stack' ] ]
            ActionMode: CHANGE_SET_REPLACE
            Capabilities: CAPABILITY_NAMED_IAM
            RoleArn: !GetAtt CodePipelineServiceRole.Arn
            ChangeSetName: !Ref ChangeSetName
            TemplateConfiguration: SourceOutput::IAC/parameters-prd.json
            TemplatePath: SourceOutput::IAC/application-stack.yml
          RunOrder: 2
      - Name: Approval
        Actions:
        - Name: ApproveOrDeny
          ActionTypeId:
            Category: Approval
            Owner: AWS
            Version: '1'
            Provider: Manual
          Configuration:
            NotificationArn: !If
              - CreateNewSNSTopic
              - !Ref CodePipelineSNSTopic
              - !Ref NotificationsSNSTopic
          RunOrder: 3
      - Name: Execute
        Actions:
        - Name: ExecuteChangeSet
          ActionTypeId:
            Category: Deploy
            Owner: AWS
            Provider: CloudFormation
            Version: '1'
          Configuration:
            ActionMode: CHANGE_SET_EXECUTE
            ChangeSetName: !Ref ChangeSetName
            RoleArn: !GetAtt CodePipelineServiceRole.Arn
            StackName: !Join [ '-', [ !Ref ApplicationName, !Ref EnvironmentClass, 'Stack' ] ]
          RunOrder: 4
      ArtifactStore:
        Type: S3
        Location: !Ref CodePipelineArtifactStoreBucket
  AppPipeline:
    Type: AWS::CodePipeline::Pipeline
    Condition: STGEnvironment
    Properties:
      Name: !Join [ '-', [ !Ref ApplicationName, !Ref EnvironmentClass, 'Pipeline' ] ]
      RoleArn:
        !GetAtt CodePipelineServiceRole.Arn
      Stages:
      -
        Name: Source
        Actions:
        -
          Name: SourceAction
          ActionTypeId:
            Category: Source
            Owner: AWS
            Version: "1"
            Provider: S3
          OutputArtifacts:
            - Name: SourceOutput
          Configuration:
            S3Bucket: !Ref OutputBucket
            S3ObjectKey: !Ref SourceObjectKey
            PollForSourceChanges: true
          RunOrder: 1
      -
        Name: Unzip
        Actions:
        -
          Name: UnzipCFN
          InputArtifacts:
            - Name: SourceOutput   
          ActionTypeId:
            Category: Invoke
            Owner: AWS
            Version: "1"
            Provider: Lambda
          Configuration:
            FunctionName: !Ref UnzipCfnTemplate
            UserParameters: !Ref ProdBucketName
          RunOrder: 3
      -
        Name: Deploy
        Actions:
        -
          Name: CreateOrUpdateStack
          InputArtifacts:
            - Name: SourceOutput  
          ActionTypeId:
            Category: Deploy
            Owner: AWS
            Version: "1"
            Provider: CloudFormation
          Configuration:
            StackName: !Join [ '-', [ !Ref ApplicationName, !Ref EnvironmentClass, 'Stack' ] ]
            ActionMode: CREATE_UPDATE
            Capabilities: CAPABILITY_NAMED_IAM
            RoleArn: !GetAtt CodePipelineServiceRole.Arn
            TemplateConfiguration: SourceOutput::IAC/parameters-stg.json
            TemplatePath: SourceOutput::IAC/application-stack.yml
          RunOrder: 2
      -
        Name: TriggerProdDeployment
        Actions:
        -
          Name: LambdaIAC
          InputArtifacts:
            - Name: SourceOutput   
          ActionTypeId:
            Category: Invoke
            Owner: AWS
            Version: "1"
            Provider: Lambda
          Configuration:
            FunctionName: !Ref UploadArtifactToProd
            UserParameters: !Ref ProdBucketName
          RunOrder: 3          
      ArtifactStore:
        Type: S3
        Location: !Ref CodePipelineArtifactStoreBucket
      


  CodeBuildPreDeployTest:
    Type: AWS::CodeBuild::Project
    Properties: 
      Artifacts:
        Type: CODEPIPELINE
      Environment: 
        ComputeType: BUILD_GENERAL1_SMALL
        Image: "aws/codebuild/python:3.7.1-1.7.0"
        Type: LINUX_CONTAINER
        #Environment Variables: #Use these to pass environment specific conditions, much like OS Variables
      LogsConfig: 
        CloudWatchLogs:
          Status: ENABLED
      ServiceRole: !GetAtt CodeBuildRole.Arn
      Source:
        BuildSpec: !Ref PreDeployBuildSpec
        Type: CODEPIPELINE
      Tags: 
        - Key: ApplicationName
          Value: !Ref ApplicationName
        - Key: EnvironmentClass
          Value: !Ref EnvironmentClass 
      #VPCConfig: #Implement this in order to specify and secure build workloads into private subnets.     
  CodeBuildRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: "2012-10-17"
        Statement:
          Effect: Allow
          Principal:
            Service: codebuild.amazonaws.com
          Action: sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/AdministratorAccess #Lock this down as needed.
  CodeBuildPostDeployTest:
    Type: AWS::CodeBuild::Project
    Properties: 
      Artifacts:
        Type: CODEPIPELINE
      Environment: 
        ComputeType: BUILD_GENERAL1_SMALL
        Image: "aws/codebuild/python:3.7.1-1.7.0"
        Type: LINUX_CONTAINER
        #Environment Variables: #Use these to pass environment specific conditions, much like OS Variables
      LogsConfig: 
        CloudWatchLogs:
          Status: ENABLED
      ServiceRole: !GetAtt CodeBuildRole.Arn
      Source:
        BuildSpec: !Ref PostDeployBuildSpec
        Type: CODEPIPELINE
      Tags: 
        - Key: ApplicationName
          Value: !Ref ApplicationName
        - Key: EnvironmentClass
          Value: !Ref EnvironmentClass 
      #VPCConfig: #Implement this in order to specify and secure build workloads into private subnets.     
  UploadNestedTemplates:
    Type: AWS::Lambda::Function
    Properties:
      Description: This takes cloudformation yaml and places it in NestedTemplateBucket for CI/CD updating
      Handler: index.handler
      Role: !GetAtt LambdaServiceRole.Arn
      Runtime: python3.7
      Tags:
        - Key: ApplicationName
          Value: !Ref ApplicationName
        - Key: EnvironmentClass
          Value: !Ref EnvironmentClass
      Timeout: 60
      #VpcConfig: #Specify for uploading within specific VPCs
      Code:
        ZipFile: |
          import json
          import os
          import boto3
          import zipfile
          def handler(event, context):
              codepipeline = boto3.client('codepipeline')
              s3 = boto3.resource('s3')
              try:
                  s3bucket = event["CodePipeline.job"]["data"]["inputArtifacts"][0]["location"]["s3Location"]["bucketName"]
                  s3key = event["CodePipeline.job"]["data"]["inputArtifacts"][0]["location"]["s3Location"]["objectKey"]
                  s3target = event["CodePipeline.job"]["data"]["actionConfiguration"]["configuration"]["UserParameters"]
                  s3.meta.client.download_file(s3bucket, s3key, '/tmp/myZip.zip')
                  with zipfile.ZipFile("/tmp/myZip.zip","r") as zip_ref:
                      zip_ref.extractall("/tmp")
                      zip_ref.close()
                  os.remove('/tmp/myZip.zip')
                  myFiles = [f for f in os.listdir('/tmp') if os.path.isfile(os.path.join('/tmp', f))]
                  for file in myFiles:
                      s3.meta.client.upload_file('/tmp/'+file, s3target, file)
                  return codepipeline.put_job_success_result(jobId=event["CodePipeline.job"]["id"], currentRevision={'revision':'1', 'changeIdentifier':'1'})
              except:
                  return codepipeline.put_job_failure_result(jobId=event["CodePipeline.job"]["id"], failureDetails={'type':'JobFailed','message':'This code failed to complete successfully'})
  
  UnzipCfnTemplate:
    Type: AWS::Lambda::Function
    Condition: STGEnvironment
    Properties:
      Description: This takes the artifact and places it in the production account bucket for CI/CD.
      Handler: index.lambda_handler
      Role: !GetAtt LambdaServiceRole.Arn
      Runtime: python3.7
      Tags:
        - Key: ApplicationName
          Value: !Ref ApplicationName
        - Key: EnvironmentClass
          Value: !Ref EnvironmentClass
      Timeout: 60
      Environment:
        Variables:
          TEMPLATE_BUCKET: !Ref 'OutputBucket'
          TEMPLATE_BUCKET_KEY: !Ref 'SourceObjectKey'
      Code:
        ZipFile: |
          import urllib
          import zipfile
          import boto3
          import io
          import os
          print('Loading function')
          s3 = boto3.client('s3')
          bucket = os.environ['TEMPLATE_BUCKET']
          def lambda_handler(event, context):
          #key = urllib.unquote_plus(event['Records'][0]['s3']['object']['key'].encode('utf8'))
            key = os.environ['TEMPLATE_BUCKET_KEY']
            codepipeline = boto3.client('codepipeline')
            try:
              obj = s3.get_object(Bucket=bucket, Key=key)
              putObjects = []
              with io.BytesIO(obj["Body"].read()) as tf:
              # rewind the file
                tf.seek(0)
                # Read the file as a zipfile and process the members
                with zipfile.ZipFile(tf, mode='r') as zipf:
                  for file in zipf.infolist():
                    fileName = file.filename
                    putFile = s3.put_object(Bucket=bucket, Key=fileName, Body=zipf.read(file))
                    putObjects.append(putFile)
                    print(putFile)
                    print('success')
              return codepipeline.put_job_success_result(jobId=event["CodePipeline.job"]["id"], currentRevision={'revision':'1', 'changeIdentifier':'1'})
            except:
              return codepipeline.put_job_failure_result(jobId=event["CodePipeline.job"]["id"], failureDetails={'type':'JobFailed','message':'This code failed to complete successfully'})

  UploadArtifactToProd:
    Type: AWS::Lambda::Function
    Condition: STGEnvironment
    Properties:
      Description: This takes the artifact and places it in the production account bucket for CI/CD.
      Handler: index.handler
      Role: !GetAtt LambdaServiceRole.Arn
      Runtime: python3.7
      Tags:
        - Key: ApplicationName
          Value: !Ref ApplicationName
        - Key: EnvironmentClass
          Value: !Ref EnvironmentClass
      Timeout: 60
      #VpcConfig: #Specify for uploading within specific VPCs
      Code:
        ZipFile: |
          import os
          import boto3
          import zipfile
          import logging
          def handler(event, context):
              logger = logging.getLogger()
              logger.setLevel(logging.INFO)
              logger.handlers[0].setFormatter(logging.Formatter('[%(asctime)s][%(levelname)s] %(message)s'))
              logging.getLogger('boto3').setLevel(logging.ERROR)
              logging.getLogger('botocore').setLevel(logging.ERROR)
              codepipeline = boto3.client('codepipeline')
              s3 = boto3.resource('s3')
              try:
                  s3bucket = event["CodePipeline.job"]["data"]["inputArtifacts"][0]["location"]["s3Location"]["bucketName"]
                  s3key = event["CodePipeline.job"]["data"]["inputArtifacts"][0]["location"]["s3Location"]["objectKey"]
                  s3target = event["CodePipeline.job"]["data"]["actionConfiguration"]["configuration"]["UserParameters"]
                  s3.meta.client.download_file(s3bucket, s3key, '/tmp/bundle.zip')
                  s3.meta.client.upload_file('/tmp/bundle.zip', s3target , 'master/bundle.zip', ExtraArgs={'ServerSideEncryption':'AES256','ACL':'bucket-owner-full-control'})
                  newKey = 'master/bundle.zip'
                  obj = s3.get_object(Bucket=s3target, Key=newKey)
                  putObjects = []
                  with io.BytesIO(obj["Body"].read()) as tf:
                    tf.seek(0)
                    with zipfile.ZipFile(tf, mode='r') as zipf:
                      for file in zipf.infolist():
                        fileName = file.filename
                        putFile = s3.put_object(Bucket=bucket, Key=fileName, Body=zipf.read(file))
                        putObjects.append(putFile)
                        print(putFile)
                        print('success')
                  return codepipeline.put_job_success_result(jobId=event["CodePipeline.job"]["id"], currentRevision={'revision':'1', 'changeIdentifier':'1'})
              except Exception as e:
                  logger.info('Error %s', e)
                  return codepipeline.put_job_failure_result(jobId=event["CodePipeline.job"]["id"], failureDetails={'type':'JobFailed','message':'This code failed to complete successfully'})
  Codepipelinestatusfunction:
    Type: AWS::Lambda::Function
    Condition: NotSTGEnvironment
    Properties:
      Description: Function to send Success or failure to pipeline to slack.
      Handler: index.handler
      Role: !GetAtt LambdaServiceRole.Arn
      Runtime: python2.7
      Tags:
        - Key: ApplicationName
          Value: !Ref ApplicationName
        - Key: EnvironmentClass
          Value: !Ref EnvironmentClass
      Timeout: 300
      Environment:
        Variables:
          SLACK_WEBHOOK_URL: !Ref 'SlackWebhookUrl'
          SLACK_CHANNEL: !Ref 'SlackChannel'
          STACK_NAME: !Join [ '-', [ !Ref ApplicationName, !Ref EnvironmentClass, 'Stack' ] ]
      #VpcConfig: #Specify for uploading within specific VPCs
      Code:
        ZipFile: |
          import json
          import logging
          import os
          from urllib2 import Request, urlopen, URLError, HTTPError
          # Read environment variables
          SLACK_WEBHOOK_URL = os.environ['SLACK_WEBHOOK_URL']
          SLACK_CHANNEL = os.environ['SLACK_CHANNEL']
          STACK_NAME = os.environ['STACK_NAME']
          logger = logging.getLogger()
          logger.setLevel(logging.INFO)
          def handler(event, context):
              logger.info("Event: " + str(event))
              # Read message posted on SNS Topic
              message = json.loads(event['Records'][0]['Sns']['Message'])
              logger.info("Message: " + str(message))
          # Construct a slack message
              slack_message = {
                  'channel': SLACK_CHANNEL,
                  'text': "%s" % (message)
              }
          # Post message on SLACK_WEBHOOK_URL
              req = Request(SLACK_WEBHOOK_URL, json.dumps(slack_message))
              try:
                  response = urlopen(req)
                  response.read()
                  logger.info("Message posted to %s", slack_message['channel'])
              except HTTPError as e:
                  logger.error("Request failed: %d %s", e.code, e.reason)
              except URLError as e:
                  logger.error("Server connection failed: %s", e.reason)   
  CodepipelinestatusAuthorizerSns:
    Type: AWS::Lambda::Permission
    Condition: NotSTGEnvironment
    Properties:
      FunctionName: !GetAtt 'Codepipelinestatusfunction.Arn'
      Action: lambda:InvokeFunction
      Principal: sns.amazonaws.com
      SourceArn: !Ref pipelinesevent                

Outputs:
  LambdaRole:
    Condition: STGEnvironment
    Description: Use this output when defining which role should populate StageLambdaRole
    Value: !Ref LambdaServiceRole
  AccountID:
    Description: Use this output when defining which Account ID should populate StageAccountId
    Value: !Ref AWS::AccountId
  GitPullWebHookApi:
    Condition: STGEnvironment
    Value:
      Fn::Join:
      - ''
      - - ' https://'
        - Ref: WebHookApi
        - .execute-api.
        - Ref: AWS::Region
        - .amazonaws.com/
        - Ref: WebHookApiProdStage
        - /gitpull
  OutputBucketName:
    Value:
      Ref: CodePipelineArtifactStoreBucket
  OutputBucket:
    Value: !Ref OutputBucket
    Description: this is the bucket where gitpull places the zip file
  PublicSSHKey:
    Condition: STGEnvironment
    Value:
      Ref: CreateSSHKey